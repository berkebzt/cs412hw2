{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "berkedeniz_bozyigit_berke.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMzUXgel6No1"
      },
      "source": [
        "# **CS412 - Machine Learning - 2022**\n",
        "## Assignment #2\n",
        "100 pts\n",
        "\n",
        "\n",
        "## Goal\n",
        "\n",
        "The goal of this homework is two-fold:\n",
        "\n",
        "*   Gain experience with neural network approaches\n",
        "*   Gain experience with the Keras library\n",
        "\n",
        "## Dataset\n",
        "You are going to use a house price dataset that we prepared for you, that contains four independent variables (predictors) and one target variable. The task is predicting the target variable (house price) from the predictors (house attributes).\n",
        "\n",
        "\n",
        "Download the data from SuCourse. Reserve 10% of the training data for validation and use the rest for development (learning your models). The official test data we provide (1,200 samples) should only be used for testing at the end, and not model selection.\n",
        "\n",
        "## Task \n",
        "Build a regressor with a neural network that has only one hidden layer, using the Keras library function calls to predict house prices in the provided dataset.\n",
        "\n",
        "Your code should follow the given skeleton and try the indicated parameters.\n",
        "\n",
        "## Preprocessing and Meta-parameters\n",
        "You should try 10,50 and 100 as hidden node count. \n",
        "\n",
        "You should  decide on the learning rate (step size), you can try values such as 0.001, 0.01, 0.1, but you may need to increase if learning is very slow or decrease if you see the loss increase!\n",
        "\n",
        "You can use either sigmoid or Relu activations for the hidden nodes (indicate with your results) and you should know what to use for the activation for the output layer, input, output layer sizes, and the suitable loss function. \n",
        "\n",
        "## Software: \n",
        "\n",
        "Keras is a library that we will use especially for deep learning, but also with basic neural network functionality of course.\n",
        "\n",
        "You may find the necessary function references here: \n",
        "\n",
        "http://scikit-learn.org/stable/supervised_learning.html\n",
        "https://keras.io/api/\n",
        "\n",
        "When you search for Dense for instance, you should find the relevant function and explained parameters, easily.\n",
        "\n",
        "## Submission: \n",
        "\n",
        "Fill this notebook. Write the report section at the end.\n",
        "\n",
        "You should prepare a separate pdf document as your homework (name hw2-CS412-yourname.pdf) which consists of the report (Part 8) of the notebook for easy viewing -and- include a link to your notebook from within the pdf report (make sure to include the link obtained from the #share link on top right, **be sure to share with Sabancı University first** as otherwise there will be access problems.). Also, do not forget to add your answers for Questions 2 and 3 on the assignment document."
      ],
      "id": "vMzUXgel6No1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBtSa7Pc8tCn"
      },
      "source": [
        "##1) Initialize\n",
        "\n",
        "*   First make a copy of the notebook given to you as a starter.\n",
        "\n",
        "*   Make sure you choose Connect form upper right.\n"
      ],
      "id": "cBtSa7Pc8tCn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFNmGxqa9G2O"
      },
      "source": [
        "## 2) Load training dataset\n",
        "\n",
        "* Load the datasets (train.csv, test.csv) provided on SuCourse on your Google drive and read the datasets using Google Drive's mount functions. \n",
        "You may find the necessary functions here: \n",
        "https://colab.research.google.com/notebooks/io.ipynb"
      ],
      "id": "hFNmGxqa9G2O"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nza2i-JK92eu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a096b4-9efa-4c52-cb9d-5f1949df02ed"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/') \n",
        "# click on the url that pops up and give the necessary authorizations"
      ],
      "id": "nza2i-JK92eu",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9P--030AOoK"
      },
      "source": [
        "\n",
        "\n",
        "*   Set your notebooks working directory to the path where the datasets are uploaded (cd is the linux command for change directory) \n",
        "*   You may need to use cd drive/MyDrive depending on your path to the datasets on Google Drive. (don't comment the code in the cells when using linux commands)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "s9P--030AOoK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lplqod5D_cf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c75bbd5f-402f-4b6d-a94d-25a0695d03ea"
      },
      "source": [
        "cd drive/My\\ Drive"
      ],
      "id": "lplqod5D_cf1",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive'\n",
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfMT3IgEAugF"
      },
      "source": [
        "* List the files in the current directory."
      ],
      "id": "IfMT3IgEAugF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoopxfoX-VOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b752f4-d35f-4b18-d261-ae5805e4fdb8"
      },
      "source": [
        "ls"
      ],
      "id": "aoopxfoX-VOq",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 25259-round1-tweet.txt        test.csv               tweet_metadata.jsons.gz\n",
            " 25259-round1-user.txt         train.csv              user_profiles.jsons\n",
            "\u001b[0m\u001b[01;34m'Colab Notebooks'\u001b[0m/             training-tweet.csv     user_profiles.jsons.gz\n",
            " evaluation-round1-tweet.csv   training-user.csv      user_tweets.jsons\n",
            " evaluation-round1-user.csv    tweet_metadata.jsons   user_tweets.jsons.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZh3Y5AlBHAs"
      },
      "source": [
        "##3) Understanding the dataset (5 pts)\n",
        "\n",
        "There are alot of functions that can be used to know more about this dataset\n",
        "\n",
        "- What is the shape of the training set (num of samples X number of attributes) **[shape function can be used]**\n",
        "\n",
        "- Display attribute names **[columns function can be used]**\n",
        "\n",
        "- Display the first 5 rows from training dataset **[head or sample functions can be used]**\n",
        "\n",
        ".."
      ],
      "id": "fZh3Y5AlBHAs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "658e2be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "a4b29455-f0c4-4d11-a525-cdf72beba731"
      },
      "source": [
        "# import the necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import mean_absolute_error as MAE\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# show first 10 elements of the training data\n",
        "train_df.head(10)"
      ],
      "id": "658e2be2",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sqmtrs  nrooms   view crime_rate          price\n",
              "0     251       5   west        low  925701.721399\n",
              "1     211       3   west       high  622237.482636\n",
              "2     128       5   east        low  694998.182376\n",
              "3     178       3   east       high  564689.015926\n",
              "4     231       3   west        low  811222.970379\n",
              "5     253       5  north       high  766250.032506\n",
              "6     101       1  north        low  512749.401548\n",
              "7     242       1  north       high  637010.760148\n",
              "8     174       5   west       high  638136.374869\n",
              "9     328       2  south       high  787704.988273"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0aee16b-2d98-407a-b6ac-7b746f56dfc7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sqmtrs</th>\n",
              "      <th>nrooms</th>\n",
              "      <th>view</th>\n",
              "      <th>crime_rate</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>251</td>\n",
              "      <td>5</td>\n",
              "      <td>west</td>\n",
              "      <td>low</td>\n",
              "      <td>925701.721399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>211</td>\n",
              "      <td>3</td>\n",
              "      <td>west</td>\n",
              "      <td>high</td>\n",
              "      <td>622237.482636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>128</td>\n",
              "      <td>5</td>\n",
              "      <td>east</td>\n",
              "      <td>low</td>\n",
              "      <td>694998.182376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>178</td>\n",
              "      <td>3</td>\n",
              "      <td>east</td>\n",
              "      <td>high</td>\n",
              "      <td>564689.015926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>231</td>\n",
              "      <td>3</td>\n",
              "      <td>west</td>\n",
              "      <td>low</td>\n",
              "      <td>811222.970379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>253</td>\n",
              "      <td>5</td>\n",
              "      <td>north</td>\n",
              "      <td>high</td>\n",
              "      <td>766250.032506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>101</td>\n",
              "      <td>1</td>\n",
              "      <td>north</td>\n",
              "      <td>low</td>\n",
              "      <td>512749.401548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>242</td>\n",
              "      <td>1</td>\n",
              "      <td>north</td>\n",
              "      <td>high</td>\n",
              "      <td>637010.760148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>174</td>\n",
              "      <td>5</td>\n",
              "      <td>west</td>\n",
              "      <td>high</td>\n",
              "      <td>638136.374869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>328</td>\n",
              "      <td>2</td>\n",
              "      <td>south</td>\n",
              "      <td>high</td>\n",
              "      <td>787704.988273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0aee16b-2d98-407a-b6ac-7b746f56dfc7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b0aee16b-2d98-407a-b6ac-7b746f56dfc7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b0aee16b-2d98-407a-b6ac-7b746f56dfc7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12bbf0c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca416d2a-9408-455b-e51e-10fa20fa1390"
      },
      "source": [
        "# print the shape of data\n",
        "\n",
        "print(\"Data dimensionality is: \", train_df.shape,\"\\n\")\n",
        "\n",
        "# also give some statistics about the data like mean, standard deviation etc.\n",
        "\n"
      ],
      "id": "12bbf0c6",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data dimensionality is:  (4800, 5) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfe277e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f641371e-c5e5-4e7e-86d7-dc6bde81b019"
      },
      "source": [
        "print(\"mean:\\n\",train_df.mean(),\"\\n\")\n",
        "print(\"standard deviation:\\n\",train_df.std())"
      ],
      "id": "dfe277e0",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean:\n",
            " sqmtrs       225.033542\n",
            "nrooms         2.983958\n",
            "price     725756.960758\n",
            "dtype: float64 \n",
            "\n",
            "standard deviation:\n",
            " sqmtrs        71.851436\n",
            "nrooms         1.421251\n",
            "price     151041.121658\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtBJzQ6NB1Kz"
      },
      "source": [
        "##4) Preprocessing Steps (10 pts)\n",
        "\n",
        "As some of the features (predictive variables) on this dataset are categorical (non-numeric) you need to do some preprocessing for those features.\n",
        "\n",
        "You can use as many **dummy or indicator variables** as there are categories within one feature. You can also look at pandas' get_dummies or keras.utils.to_categorical functions.\n",
        "\n",
        "In neural networks, scaling of the features are important, because they affect the net input of a neuron as a whole. You should use **MinMax scaler** on sklearn for this task, which scales the variables between 0 and 1 on by default. (Remember that mean-squared error loss function tends to be extremely large with unscaled features.)\n"
      ],
      "id": "GtBJzQ6NB1Kz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b505bf7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "38ba984b-565b-4c96-aa88-52ea11fea5de"
      },
      "source": [
        "# encode the categorical variables\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "train_df[\"view\"] = le.fit_transform(train_df[\"view\"])\n",
        "train_df[\"crime_rate\"] = le.fit_transform(train_df[\"crime_rate\"])\n",
        "\n",
        "# scale the features between 0-1\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "msc = MinMaxScaler()\n",
        "train_df[[\"sqmtrs\",\"nrooms\",\"view\",\"crime_rate\",\"price\"]] = msc.fit_transform(train_df[[\"sqmtrs\",\"nrooms\",\"view\",\"crime_rate\",\"price\"]])\n",
        "\n",
        "train_df\n",
        "\n"
      ],
      "id": "b505bf7b",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        sqmtrs  nrooms      view  crime_rate     price\n",
              "0     0.606426    1.00  1.000000         1.0  0.791034\n",
              "1     0.445783    0.50  1.000000         0.0  0.369303\n",
              "2     0.112450    1.00  0.000000         1.0  0.470421\n",
              "3     0.313253    0.50  0.000000         0.0  0.289327\n",
              "4     0.526104    0.50  1.000000         1.0  0.631941\n",
              "...        ...     ...       ...         ...       ...\n",
              "4795  0.526104    1.00  0.000000         1.0  0.735894\n",
              "4796  0.518072    0.25  0.000000         1.0  0.590538\n",
              "4797  0.939759    0.25  1.000000         0.0  0.597776\n",
              "4798  0.931727    0.25  0.333333         0.0  0.586529\n",
              "4799  0.578313    0.75  0.000000         1.0  0.709510\n",
              "\n",
              "[4800 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b414c228-6467-4010-8ac4-0d828f5a0281\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sqmtrs</th>\n",
              "      <th>nrooms</th>\n",
              "      <th>view</th>\n",
              "      <th>crime_rate</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.606426</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.791034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.445783</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.369303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.112450</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.470421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.313253</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.289327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.526104</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.631941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>0.526104</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.735894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>0.518072</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.590538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>0.939759</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.597776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>0.931727</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.586529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>0.578313</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.709510</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4800 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b414c228-6467-4010-8ac4-0d828f5a0281')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b414c228-6467-4010-8ac4-0d828f5a0281 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b414c228-6467-4010-8ac4-0d828f5a0281');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnSUvg-OK9FP"
      },
      "source": [
        "Don't forget the split the training data to obtain a validation set. **Use random_state=42**"
      ],
      "id": "nnSUvg-OK9FP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WufovdxNK8sI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28260538-f22f-40f4-9745-1b7afb4dfacd"
      },
      "source": [
        "# split 90-10\n",
        "\n",
        "train_df, val_df = np.split(train_df.sample(frac=1, random_state=42), [int(.9*len(train_df))])\n",
        "print(\"len train:\",len(train_df))\n",
        "print(\"len val:\",len(val_df))"
      ],
      "id": "WufovdxNK8sI",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len train: 4320\n",
            "len val: 480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU-_nQ4IFuR3"
      },
      "source": [
        "##5) Train neural networks on development data and do model selection using the validation data (55 pts)\n",
        "\n",
        "\n",
        "* Train a neural network with **one hidden layer** (try 3 different values for the number of neurons in that hidden layer, as 25, 50, 100), you will need to correctly choose the optimizer and the loss function that this model will train with. Use batch_size as 64 and train each model for 30 epochs. \n",
        "\n",
        "* Train another neural network with two hidden layers with meta-parameters of your choice. Again, use batch_size as 64 and train the model for 30 epochs. \n",
        "\n",
        "* **Bonus (5 pts)** Train a KNN or a Decision Tree model with your own choice of meta parameters to predict the house prices.\n"
      ],
      "id": "hU-_nQ4IFuR3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bec4fb64"
      },
      "source": [
        "# train one-hidden layered neural networks\n",
        "# define your model architecture\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "model_onehidden_25 = Sequential()\n",
        "model_onehidden_25.add(Flatten())\n",
        "model_onehidden_25.add(Dense(25, activation='sigmoid', name='hidden_1'))\n",
        "model_onehidden_25.add(Dense(25, activation='softmax', name='output_layer'))\n",
        "\n",
        "model_onehidden_50 = Sequential()\n",
        "model_onehidden_50.add(Flatten())\n",
        "model_onehidden_50.add(Dense(50, activation='sigmoid', name='hidden_1'))\n",
        "model_onehidden_50.add(Dense(50, activation='softmax', name='output_layer'))\n",
        "\n",
        "model_onehidden_100 = Sequential()\n",
        "model_onehidden_100.add(Flatten())\n",
        "model_onehidden_100.add(Dense(100, activation='sigmoid', name='hidden_1'))\n",
        "model_onehidden_100.add(Dense(100, activation='softmax', name='output_layer'))"
      ],
      "id": "bec4fb64",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvsgI7rWI1ST"
      },
      "source": [
        "# compile your model with an optimizer\n",
        "model_onehidden_25.compile(loss='mean_squared_error', optimizer= Adam(learning_rate = 0.1))\n",
        "model_onehidden_50.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model_onehidden_100.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "id": "rvsgI7rWI1ST",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0LsRGBOJChq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690950e3-5c01-4d43-f0fe-bbe7f5049f7a"
      },
      "source": [
        "# fit the model on training data\n",
        "model_onehidden_25.fit(train_df.loc[:, train_df.columns != 'price'].values, train_df[\"price\"].values, batch_size=64, epochs=30, verbose=2)\n",
        "model_onehidden_50.fit(train_df.loc[:, train_df.columns != 'price'].values, train_df[\"price\"].values, batch_size=64, epochs=30, verbose=2)\n",
        "model_onehidden_100.fit(train_df.loc[:, train_df.columns != 'price'].values, train_df[\"price\"].values, batch_size=64, epochs=30, verbose=2)"
      ],
      "id": "z0LsRGBOJChq",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "68/68 - 1s - loss: 0.2680 - 507ms/epoch - 7ms/step\n",
            "Epoch 2/30\n",
            "68/68 - 0s - loss: 0.2679 - 114ms/epoch - 2ms/step\n",
            "Epoch 3/30\n",
            "68/68 - 0s - loss: 0.2679 - 124ms/epoch - 2ms/step\n",
            "Epoch 4/30\n",
            "68/68 - 0s - loss: 0.2679 - 118ms/epoch - 2ms/step\n",
            "Epoch 5/30\n",
            "68/68 - 0s - loss: 0.2679 - 118ms/epoch - 2ms/step\n",
            "Epoch 6/30\n",
            "68/68 - 0s - loss: 0.2679 - 127ms/epoch - 2ms/step\n",
            "Epoch 7/30\n",
            "68/68 - 0s - loss: 0.2679 - 139ms/epoch - 2ms/step\n",
            "Epoch 8/30\n",
            "68/68 - 0s - loss: 0.2679 - 120ms/epoch - 2ms/step\n",
            "Epoch 9/30\n",
            "68/68 - 0s - loss: 0.2679 - 117ms/epoch - 2ms/step\n",
            "Epoch 10/30\n",
            "68/68 - 0s - loss: 0.2679 - 121ms/epoch - 2ms/step\n",
            "Epoch 11/30\n",
            "68/68 - 0s - loss: 0.2679 - 137ms/epoch - 2ms/step\n",
            "Epoch 12/30\n",
            "68/68 - 0s - loss: 0.2679 - 141ms/epoch - 2ms/step\n",
            "Epoch 13/30\n",
            "68/68 - 0s - loss: 0.2679 - 118ms/epoch - 2ms/step\n",
            "Epoch 14/30\n",
            "68/68 - 0s - loss: 0.2679 - 113ms/epoch - 2ms/step\n",
            "Epoch 15/30\n",
            "68/68 - 0s - loss: 0.2679 - 107ms/epoch - 2ms/step\n",
            "Epoch 16/30\n",
            "68/68 - 0s - loss: 0.2679 - 116ms/epoch - 2ms/step\n",
            "Epoch 17/30\n",
            "68/68 - 0s - loss: 0.2679 - 109ms/epoch - 2ms/step\n",
            "Epoch 18/30\n",
            "68/68 - 0s - loss: 0.2679 - 125ms/epoch - 2ms/step\n",
            "Epoch 19/30\n",
            "68/68 - 0s - loss: 0.2679 - 141ms/epoch - 2ms/step\n",
            "Epoch 20/30\n",
            "68/68 - 0s - loss: 0.2679 - 115ms/epoch - 2ms/step\n",
            "Epoch 21/30\n",
            "68/68 - 0s - loss: 0.2679 - 112ms/epoch - 2ms/step\n",
            "Epoch 22/30\n",
            "68/68 - 0s - loss: 0.2679 - 105ms/epoch - 2ms/step\n",
            "Epoch 23/30\n",
            "68/68 - 0s - loss: 0.2679 - 117ms/epoch - 2ms/step\n",
            "Epoch 24/30\n",
            "68/68 - 0s - loss: 0.2679 - 120ms/epoch - 2ms/step\n",
            "Epoch 25/30\n",
            "68/68 - 0s - loss: 0.2679 - 114ms/epoch - 2ms/step\n",
            "Epoch 26/30\n",
            "68/68 - 0s - loss: 0.2679 - 99ms/epoch - 1ms/step\n",
            "Epoch 27/30\n",
            "68/68 - 0s - loss: 0.2679 - 119ms/epoch - 2ms/step\n",
            "Epoch 28/30\n",
            "68/68 - 0s - loss: 0.2679 - 110ms/epoch - 2ms/step\n",
            "Epoch 29/30\n",
            "68/68 - 0s - loss: 0.2679 - 116ms/epoch - 2ms/step\n",
            "Epoch 30/30\n",
            "68/68 - 0s - loss: 0.2679 - 102ms/epoch - 2ms/step\n",
            "Epoch 1/30\n",
            "68/68 - 1s - loss: 0.2872 - 577ms/epoch - 8ms/step\n",
            "Epoch 2/30\n",
            "68/68 - 0s - loss: 0.2872 - 117ms/epoch - 2ms/step\n",
            "Epoch 3/30\n",
            "68/68 - 0s - loss: 0.2872 - 121ms/epoch - 2ms/step\n",
            "Epoch 4/30\n",
            "68/68 - 0s - loss: 0.2872 - 143ms/epoch - 2ms/step\n",
            "Epoch 5/30\n",
            "68/68 - 0s - loss: 0.2872 - 139ms/epoch - 2ms/step\n",
            "Epoch 6/30\n",
            "68/68 - 0s - loss: 0.2872 - 157ms/epoch - 2ms/step\n",
            "Epoch 7/30\n",
            "68/68 - 0s - loss: 0.2872 - 139ms/epoch - 2ms/step\n",
            "Epoch 8/30\n",
            "68/68 - 0s - loss: 0.2872 - 128ms/epoch - 2ms/step\n",
            "Epoch 9/30\n",
            "68/68 - 0s - loss: 0.2872 - 138ms/epoch - 2ms/step\n",
            "Epoch 10/30\n",
            "68/68 - 0s - loss: 0.2872 - 127ms/epoch - 2ms/step\n",
            "Epoch 11/30\n",
            "68/68 - 0s - loss: 0.2872 - 122ms/epoch - 2ms/step\n",
            "Epoch 12/30\n",
            "68/68 - 0s - loss: 0.2872 - 126ms/epoch - 2ms/step\n",
            "Epoch 13/30\n",
            "68/68 - 0s - loss: 0.2872 - 132ms/epoch - 2ms/step\n",
            "Epoch 14/30\n",
            "68/68 - 0s - loss: 0.2872 - 171ms/epoch - 3ms/step\n",
            "Epoch 15/30\n",
            "68/68 - 0s - loss: 0.2872 - 127ms/epoch - 2ms/step\n",
            "Epoch 16/30\n",
            "68/68 - 0s - loss: 0.2872 - 129ms/epoch - 2ms/step\n",
            "Epoch 17/30\n",
            "68/68 - 0s - loss: 0.2872 - 121ms/epoch - 2ms/step\n",
            "Epoch 18/30\n",
            "68/68 - 0s - loss: 0.2872 - 115ms/epoch - 2ms/step\n",
            "Epoch 19/30\n",
            "68/68 - 0s - loss: 0.2872 - 121ms/epoch - 2ms/step\n",
            "Epoch 20/30\n",
            "68/68 - 0s - loss: 0.2872 - 124ms/epoch - 2ms/step\n",
            "Epoch 21/30\n",
            "68/68 - 0s - loss: 0.2872 - 130ms/epoch - 2ms/step\n",
            "Epoch 22/30\n",
            "68/68 - 0s - loss: 0.2872 - 118ms/epoch - 2ms/step\n",
            "Epoch 23/30\n",
            "68/68 - 0s - loss: 0.2872 - 126ms/epoch - 2ms/step\n",
            "Epoch 24/30\n",
            "68/68 - 0s - loss: 0.2872 - 131ms/epoch - 2ms/step\n",
            "Epoch 25/30\n",
            "68/68 - 0s - loss: 0.2872 - 132ms/epoch - 2ms/step\n",
            "Epoch 26/30\n",
            "68/68 - 0s - loss: 0.2872 - 124ms/epoch - 2ms/step\n",
            "Epoch 27/30\n",
            "68/68 - 0s - loss: 0.2872 - 118ms/epoch - 2ms/step\n",
            "Epoch 28/30\n",
            "68/68 - 0s - loss: 0.2872 - 126ms/epoch - 2ms/step\n",
            "Epoch 29/30\n",
            "68/68 - 0s - loss: 0.2872 - 140ms/epoch - 2ms/step\n",
            "Epoch 30/30\n",
            "68/68 - 0s - loss: 0.2872 - 124ms/epoch - 2ms/step\n",
            "Epoch 1/30\n",
            "68/68 - 1s - loss: 0.2972 - 555ms/epoch - 8ms/step\n",
            "Epoch 2/30\n",
            "68/68 - 0s - loss: 0.2972 - 160ms/epoch - 2ms/step\n",
            "Epoch 3/30\n",
            "68/68 - 0s - loss: 0.2972 - 170ms/epoch - 2ms/step\n",
            "Epoch 4/30\n",
            "68/68 - 0s - loss: 0.2972 - 146ms/epoch - 2ms/step\n",
            "Epoch 5/30\n",
            "68/68 - 0s - loss: 0.2972 - 150ms/epoch - 2ms/step\n",
            "Epoch 6/30\n",
            "68/68 - 0s - loss: 0.2972 - 142ms/epoch - 2ms/step\n",
            "Epoch 7/30\n",
            "68/68 - 0s - loss: 0.2972 - 151ms/epoch - 2ms/step\n",
            "Epoch 8/30\n",
            "68/68 - 0s - loss: 0.2972 - 139ms/epoch - 2ms/step\n",
            "Epoch 9/30\n",
            "68/68 - 0s - loss: 0.2972 - 174ms/epoch - 3ms/step\n",
            "Epoch 10/30\n",
            "68/68 - 0s - loss: 0.2972 - 160ms/epoch - 2ms/step\n",
            "Epoch 11/30\n",
            "68/68 - 0s - loss: 0.2972 - 151ms/epoch - 2ms/step\n",
            "Epoch 12/30\n",
            "68/68 - 0s - loss: 0.2972 - 135ms/epoch - 2ms/step\n",
            "Epoch 13/30\n",
            "68/68 - 0s - loss: 0.2972 - 142ms/epoch - 2ms/step\n",
            "Epoch 14/30\n",
            "68/68 - 0s - loss: 0.2972 - 142ms/epoch - 2ms/step\n",
            "Epoch 15/30\n",
            "68/68 - 0s - loss: 0.2972 - 141ms/epoch - 2ms/step\n",
            "Epoch 16/30\n",
            "68/68 - 0s - loss: 0.2972 - 157ms/epoch - 2ms/step\n",
            "Epoch 17/30\n",
            "68/68 - 0s - loss: 0.2972 - 148ms/epoch - 2ms/step\n",
            "Epoch 18/30\n",
            "68/68 - 0s - loss: 0.2972 - 148ms/epoch - 2ms/step\n",
            "Epoch 19/30\n",
            "68/68 - 0s - loss: 0.2972 - 150ms/epoch - 2ms/step\n",
            "Epoch 20/30\n",
            "68/68 - 0s - loss: 0.2972 - 132ms/epoch - 2ms/step\n",
            "Epoch 21/30\n",
            "68/68 - 0s - loss: 0.2972 - 127ms/epoch - 2ms/step\n",
            "Epoch 22/30\n",
            "68/68 - 0s - loss: 0.2972 - 159ms/epoch - 2ms/step\n",
            "Epoch 23/30\n",
            "68/68 - 0s - loss: 0.2972 - 149ms/epoch - 2ms/step\n",
            "Epoch 24/30\n",
            "68/68 - 0s - loss: 0.2972 - 139ms/epoch - 2ms/step\n",
            "Epoch 25/30\n",
            "68/68 - 0s - loss: 0.2972 - 139ms/epoch - 2ms/step\n",
            "Epoch 26/30\n",
            "68/68 - 0s - loss: 0.2972 - 144ms/epoch - 2ms/step\n",
            "Epoch 27/30\n",
            "68/68 - 0s - loss: 0.2972 - 174ms/epoch - 3ms/step\n",
            "Epoch 28/30\n",
            "68/68 - 0s - loss: 0.2972 - 149ms/epoch - 2ms/step\n",
            "Epoch 29/30\n",
            "68/68 - 0s - loss: 0.2972 - 171ms/epoch - 3ms/step\n",
            "Epoch 30/30\n",
            "68/68 - 0s - loss: 0.2972 - 166ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f57f1ec13d0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13b3d502",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba63487-8812-4223-c93f-45fe45dda16b"
      },
      "source": [
        "# train a two-hidden layered neural network\n",
        "model_twohidden = Sequential()\n",
        "model_twohidden.add(Flatten())\n",
        "model_twohidden.add(Dense(25, activation='sigmoid', name='hidden_1'))\n",
        "model_twohidden.add(Dense(50, activation='sigmoid', name='hidden_2'))\n",
        "model_twohidden.add(Dense(10, activation='softmax', name='output_layer'))\n",
        "model_twohidden.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model_twohidden.fit(train_df.loc[:, train_df.columns != 'price'].values, train_df[\"price\"].values, batch_size=64, epochs=30, verbose=2)\n",
        "# ...\n"
      ],
      "id": "13b3d502",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "68/68 - 1s - loss: 0.2151 - 703ms/epoch - 10ms/step\n",
            "Epoch 2/30\n",
            "68/68 - 0s - loss: 0.2148 - 141ms/epoch - 2ms/step\n",
            "Epoch 3/30\n",
            "68/68 - 0s - loss: 0.2148 - 141ms/epoch - 2ms/step\n",
            "Epoch 4/30\n",
            "68/68 - 0s - loss: 0.2148 - 146ms/epoch - 2ms/step\n",
            "Epoch 5/30\n",
            "68/68 - 0s - loss: 0.2148 - 157ms/epoch - 2ms/step\n",
            "Epoch 6/30\n",
            "68/68 - 0s - loss: 0.2148 - 166ms/epoch - 2ms/step\n",
            "Epoch 7/30\n",
            "68/68 - 0s - loss: 0.2148 - 144ms/epoch - 2ms/step\n",
            "Epoch 8/30\n",
            "68/68 - 0s - loss: 0.2148 - 121ms/epoch - 2ms/step\n",
            "Epoch 9/30\n",
            "68/68 - 0s - loss: 0.2148 - 137ms/epoch - 2ms/step\n",
            "Epoch 10/30\n",
            "68/68 - 0s - loss: 0.2148 - 127ms/epoch - 2ms/step\n",
            "Epoch 11/30\n",
            "68/68 - 0s - loss: 0.2148 - 123ms/epoch - 2ms/step\n",
            "Epoch 12/30\n",
            "68/68 - 0s - loss: 0.2148 - 127ms/epoch - 2ms/step\n",
            "Epoch 13/30\n",
            "68/68 - 0s - loss: 0.2148 - 139ms/epoch - 2ms/step\n",
            "Epoch 14/30\n",
            "68/68 - 0s - loss: 0.2148 - 129ms/epoch - 2ms/step\n",
            "Epoch 15/30\n",
            "68/68 - 0s - loss: 0.2148 - 136ms/epoch - 2ms/step\n",
            "Epoch 16/30\n",
            "68/68 - 0s - loss: 0.2148 - 119ms/epoch - 2ms/step\n",
            "Epoch 17/30\n",
            "68/68 - 0s - loss: 0.2148 - 133ms/epoch - 2ms/step\n",
            "Epoch 18/30\n",
            "68/68 - 0s - loss: 0.2148 - 141ms/epoch - 2ms/step\n",
            "Epoch 19/30\n",
            "68/68 - 0s - loss: 0.2148 - 128ms/epoch - 2ms/step\n",
            "Epoch 20/30\n",
            "68/68 - 0s - loss: 0.2148 - 143ms/epoch - 2ms/step\n",
            "Epoch 21/30\n",
            "68/68 - 0s - loss: 0.2148 - 133ms/epoch - 2ms/step\n",
            "Epoch 22/30\n",
            "68/68 - 0s - loss: 0.2148 - 128ms/epoch - 2ms/step\n",
            "Epoch 23/30\n",
            "68/68 - 0s - loss: 0.2148 - 135ms/epoch - 2ms/step\n",
            "Epoch 24/30\n",
            "68/68 - 0s - loss: 0.2148 - 134ms/epoch - 2ms/step\n",
            "Epoch 25/30\n",
            "68/68 - 0s - loss: 0.2148 - 122ms/epoch - 2ms/step\n",
            "Epoch 26/30\n",
            "68/68 - 0s - loss: 0.2148 - 131ms/epoch - 2ms/step\n",
            "Epoch 27/30\n",
            "68/68 - 0s - loss: 0.2148 - 120ms/epoch - 2ms/step\n",
            "Epoch 28/30\n",
            "68/68 - 0s - loss: 0.2148 - 144ms/epoch - 2ms/step\n",
            "Epoch 29/30\n",
            "68/68 - 0s - loss: 0.2148 - 126ms/epoch - 2ms/step\n",
            "Epoch 30/30\n",
            "68/68 - 0s - loss: 0.2148 - 133ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f586bdcab10>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BONUS PART"
      ],
      "metadata": {
        "id": "mufF_H15ii7e"
      },
      "id": "mufF_H15ii7e",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rPGNFqdINTP"
      },
      "source": [
        "## 6) Test your trained classifiers on the Validation set (10 pts)\n",
        "Test your trained classifiers on the validation set and print the mean squared errors.\n"
      ],
      "id": "4rPGNFqdINTP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9noUcsDJH1Hz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e43131-4c5a-4a9a-ba33-f759b2489249"
      },
      "source": [
        "# tests on validation\n",
        "score_onehidden_25 = model_onehidden_25.evaluate(val_df.loc[:, val_df.columns != 'price'].values, val_df[\"price\"].values, verbose=0)\n",
        "print('Validation loss of model with one hidden layer for 25 neurons:', score_onehidden_25)\n",
        "score_onehidden_50 = model_onehidden_50.evaluate(val_df.loc[:, val_df.columns != 'price'].values, val_df[\"price\"].values, verbose=0)\n",
        "print('Validation loss of model with one hidden layer for 50 neurons:', score_onehidden_50)\n",
        "score_onehidden_100 = model_onehidden_100.evaluate(val_df.loc[:, val_df.columns != 'price'].values, val_df[\"price\"].values, verbose=0)\n",
        "print('Validation loss of model with one hidden layer for 100 neurons:', score_onehidden_100)\n",
        "score_twohidden = model_twohidden.evaluate(val_df.loc[:, val_df.columns != 'price'].values, val_df[\"price\"].values, verbose=0)\n",
        "print('Validation loss of model with two hidden layers:', score_twohidden)\n",
        "#..."
      ],
      "id": "9noUcsDJH1Hz",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss of model with one hidden layer for 25 neurons: 0.26823854446411133\n",
            "Validation loss of model with one hidden layer for 50 neurons: 0.2877204120159149\n",
            "Validation loss of model with one hidden layer for 100 neurons: 0.29776135087013245\n",
            "Validation loss of model with two hidden layers: 0.2145930677652359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mojk_4Q9JQkR"
      },
      "source": [
        "## 7) Test your classifier on Test set (10 pts)\n",
        "\n",
        "- Load test data\n",
        "- Apply same pre-processing as training data (encoding categorical variables, scaling)\n",
        "- Predict the labels of testing data **using the best model that you have selected according to your validation results** and report the mean squared error. "
      ],
      "id": "mojk_4Q9JQkR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f3558e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d382b912-8756-4084-c43d-5ef57594a41d"
      },
      "source": [
        "# test results\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "test_df[\"view\"] = le.fit_transform(test_df[\"view\"])\n",
        "test_df[\"crime_rate\"] = le.fit_transform(test_df[\"crime_rate\"])\n",
        "test_df[[\"sqmtrs\",\"nrooms\",\"view\",\"crime_rate\",\"price\"]] = msc.fit_transform(test_df[[\"sqmtrs\",\"nrooms\",\"view\",\"crime_rate\",\"price\"]])\n",
        "results = model_twohidden.predict(test_df.loc[:, test_df.columns != 'price'].values)\n",
        "print('Test loss of model with two hidden layers:', score_twohidden)\n",
        "print('Test predictions:', results)\n",
        "\n"
      ],
      "id": "5f3558e8",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss of model with two hidden layers: 0.2145930677652359\n",
            "Test predictions: [[0.10016556 0.09991415 0.09993943 ... 0.10007176 0.10000078 0.10005499]\n",
            " [0.10018168 0.09990357 0.09997125 ... 0.10006765 0.10004179 0.09993698]\n",
            " [0.10005916 0.09994534 0.09997705 ... 0.10004854 0.10001284 0.0999774 ]\n",
            " ...\n",
            " [0.09993505 0.10006616 0.10006147 ... 0.09994195 0.10005982 0.0998648 ]\n",
            " [0.10011081 0.09992773 0.09995797 ... 0.10005982 0.10000726 0.10001684]\n",
            " [0.10026237 0.09994609 0.10002346 ... 0.09999225 0.10004206 0.09998269]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg0mDfdNJgrd"
      },
      "source": [
        "##8) Report Your Results (10 pts)\n",
        "\n",
        "**Notebook should be RUN:** As training and testing may take a long time, we may just look at your notebook results without running the code again; so make sure **each cell is run**, so outputs are there.\n",
        "\n",
        "**Report:** Write an **1-2 page summary** of your approach to this problem **as indicated below**. \n",
        "\n",
        "**Must include statements such as those below:**\n",
        "**(Remove the text in parentheses, below, and include your own report)**\n",
        "\n",
        "\n",
        "I have used a house price dataset, that contains four independent variables (predictors) and one target variable. The task is predicting the target variable (house price) from the predictors (house attributes).\n",
        "\n",
        "\n",
        "I have reserved 10% of the training data for validation and use the rest for training itself. The official test data was provided (1,200 samples), only be used for testing at the end, and not model selection.\n",
        "\n",
        "As some of the features (predictive variables) on this dataset are categorical (non-numeric) I need to do some preprocessing for those features.\n",
        "\n",
        "I have used MinMax scaler on sklearn for preprocessing, which scales the variables between 0 and 1 on by default.\n",
        "\n",
        "**Add your observations as follows** (keep the questions for easy grading/context) in the report part of your notebook.\n",
        "\n",
        "**Observations**\n",
        "\n",
        "- Try a few learning rates for N=25 hidden neurons,  train for the indicated amount of epochs. Comment on what happens when learning rate is large or small? What is a good number/range for the learning rate?\n",
        "If we use larger learning rates we need fewer epochs. However, when we use smaller learning rates we need more training epochs. Learning rate must not be too big or too small.\n",
        "\n",
        "- Use that learning rate and vary the number of hidden neurons for the given values and try the indicated number of epochs. Give the validation mean squared errors for different approach and meta-parameters tried **in a table** and state which one you selected as your model. How many hidden neurons give the best model? \n",
        "Your answer here….\n",
        "\n",
        "- State  what your test results are with the chosen approach and meta-parameters: e.g. \"We have obtained the best results on the validation set with the ..........approach using a value of ...... for .... parameter. The result of this model on the test data is ..... % accuracy.\"\" \n",
        "\n",
        "- How slow is learning? Any other problems?\n",
        "Your answer here….\n",
        "\n",
        "- Any other observations (not obligatory)\n",
        "\n",
        " You can add additional visualization as separate pages if you want, think of them as appendix, keeping the summary to 1-2-pages.\n",
        "\n"
      ],
      "id": "Qg0mDfdNJgrd"
    }
  ]
}